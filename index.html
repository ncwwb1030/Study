<!DOCTYPE html>
<html lang="zh-Hant">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>INFS5720</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <style>
        :root {
            --primary: #007AFF;
            --bg: #F2F2F7;
            --card-bg: #FFFFFF;
            --text: #1C1C1E;
            --success: #34C759;
            --error: #FF3B30;
            --subtext: #666;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: var(--bg);
            color: var(--text);
            padding-bottom: 85px;
            -webkit-tap-highlight-color: transparent;
        }
        
        /* Header */
        header {
            background: var(--card-bg);
            padding: 15px;
            text-align: center;
            position: sticky;
            top: 0;
            z-index: 100;
            border-bottom: 1px solid #ddd;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }
        h1 { font-size: 1.2rem; margin: 0; color: var(--text); font-weight: 700; }

        /* Tabs & Content */
        .tab-content { display: none; padding: 15px; animation: fadein 0.3s; }
        .tab-content.active { display: block; }
        @keyframes fadein { from { opacity: 0; } to { opacity: 1; } }

        /* General UI Elements */
        .card {
            background: var(--card-bg);
            border-radius: 12px;
            padding: 15px;
            margin-bottom: 15px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.03);
        }
        .section-title {
            font-size: 0.9rem;
            color: var(--subtext);
            margin: 20px 0 10px 5px;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
        }
        h2 { font-size: 1.3rem; margin-top: 0; color: var(--primary); }
        
        /* Notes (Accordion) */
        details {
            background: var(--card-bg);
            margin-bottom: 12px;
            border-radius: 10px;
            overflow: hidden;
            border: 1px solid #e5e5e5;
        }
        summary {
            padding: 15px;
            cursor: pointer;
            font-weight: 600;
            list-style: none;
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: #fff;
        }
        summary::-webkit-details-marker { display: none; }
        summary::after { content: '+'; color: var(--primary); font-size: 1.2em; font-weight: bold; }
        details[open] summary::after { content: '-'; }
        details[open] summary { border-bottom: 1px solid #eee; background: #fafafa; }
        .note-body { padding: 15px; line-height: 1.7; font-size: 0.95rem; color: #333; }
        .note-body strong { color: #000; }
        .note-body ul { padding-left: 20px; margin: 10px 0; }
        .note-body li { margin-bottom: 8px; }

        /* Question Bank & Quiz Styles */
        .q-card {
            background: #fff;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            border: 1px solid #eee;
        }
        .q-text { font-weight: 600; margin-bottom: 12px; font-size: 1rem; }
        .q-opt {
            display: block;
            width: 100%;
            padding: 12px;
            margin-bottom: 8px;
            border: 1px solid #ddd;
            border-radius: 8px;
            background: #fff;
            text-align: left;
            font-size: 0.95rem;
            cursor: pointer;
            transition: all 0.2s;
        }
        .q-opt:active { background: #f2f2f2; }
        .q-opt.correct { background: #e8f5e9; border-color: var(--success); color: #2e7d32; }
        .q-opt.wrong { background: #ffebee; border-color: var(--error); color: #c62828; }
        
        .explanation {
            margin-top: 10px;
            padding: 12px;
            background: #f1f8ff;
            border-radius: 8px;
            font-size: 0.9rem;
            color: #444;
            display: none;
            border-left: 4px solid var(--primary);
        }

        /* Buttons */
        .btn-primary {
            background: var(--primary);
            color: white;
            border: none;
            padding: 12px;
            width: 100%;
            border-radius: 10px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            margin-top: 10px;
        }

        /* Mermaid */
        .mermaid { background: white; padding: 10px; border-radius: 8px; overflow-x: auto; }

        /* Bottom Nav */
        nav {
            position: fixed;
            bottom: 0;
            left: 0;
            width: 100%;
            background: rgba(255,255,255,0.95);
            backdrop-filter: blur(10px);
            display: flex;
            justify-content: space-around;
            padding: 8px 0 25px 0; /* Extra padding for iPhone home bar */
            border-top: 1px solid #ccc;
            z-index: 1000;
        }
        .nav-item {
            text-align: center;
            font-size: 0.65rem;
            color: #8e8e93;
            flex: 1;
            cursor: pointer;
        }
        .nav-item.active { color: var(--primary); }
        .nav-icon { font-size: 1.5rem; display: block; margin-bottom: 2px; }
        
        /* Table Styles */
        table { width: 100%; border-collapse: collapse; font-size: 0.85rem; margin: 10px 0; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f8f9fa; color: var(--primary); }

    </style>
</head>
<body>

<header>
    <h1>INFS5720</h1>
</header>

<div id="tab-outline" class="tab-content active">
    <div class="card">
        <h2>ğŸ“š è€ƒè©¦å¤§ç¶±</h2>
        <p><b>å½¢å¼ï¼š</b> 55% æœŸæœ«è€ƒ (32é¡Œ MCQ + 2é¡Œç°¡ç­”)</p>
        <p><b>é‡é»ï¼š</b> æ¦‚å¿µç†è§£ã€çµæœè§£é‡‹ã€æ¨¡å‹æ¯”è¼ƒã€æ‡‰ç”¨å ´æ™¯ã€‚</p>
        <p style="color:var(--error);"><b>ä¸è€ƒï¼š</b> å¯«ç¨‹å¼ç¢¼ã€è¤‡é›œæ•¸å­¸æ¨å°ã€è¨ˆç®—æ©Ÿã€‚</p>
    </div>

    <div class="section-title">æ ¸å¿ƒçŸ¥è­˜é«”ç³»</div>
    <div class="card">
        <p><b>1. Supervised (ç›£ç£å¼)</b></p>
        <ul>
            <li>æœ‰æ¨™ç±¤ (Target Y)</li>
            <li><b>Regression (å›æ­¸)</b>: Linear, Multiple, Regularized (Ridge, LASSO)</li>
            <li><b>Classification (åˆ†é¡)</b>: Logistic, Decision Tree, ANN, Ensemble, CNN</li>
        </ul>
        <hr style="border:0; border-top:1px solid #eee;">
        <p><b>2. Unsupervised (éç›£ç£)</b></p>
        <ul>
            <li>ç„¡æ¨™ç±¤ (No Y)</li>
            <li><b>Clustering (èšé¡)</b>: Hierarchical, K-means</li>
            <li><b>Dimension Reduction (é™ç¶­)</b>: PCA</li>
        </ul>
        <hr style="border:0; border-top:1px solid #eee;">
        <p><b>3. Reinforcement (å¼·åŒ–)</b></p>
        <ul>
            <li>Agent èˆ‡ç’°å¢ƒäº’å‹•</li>
            <li><b>MAB (å¤šè‡‚è€è™æ©Ÿ)</b>: Explore vs Exploit</li>
        </ul>
    </div>
</div>

<div id="tab-mindmap" class="tab-content">
    <div class="card">
        <h2>ğŸ§  æ¨¡å‹é—œä¿‚åœ–è­œ</h2>
        <p>é›™æŒ‡ç¸®æ”¾æŸ¥çœ‹</p>
        <div class="mermaid">
            graph TD
            ML[Machine Learning]
            
            %% Supervised Branch
            ML --> SUP(Supervised<br>Target Y)
            SUP --> REG[Regression<br>Continuous Y]
            SUP --> CLS[Classification<br>Categorical Y]
            
            REG --> LR[Linear Regression]
            LR -->|Overfitting Fix| REG_FIX[Regularization]
            REG_FIX --> LASSO[Lasso L1<br>Feature Selection]
            REG_FIX --> RIDGE[Ridge L2<br>Shrink Coeffs]
            
            CLS --> LOG[Logistic Regression]
            CLS --> DT[Decision Tree<br>Rules/White Box]
            CLS --> NN[Neural Networks<br>Complex/Black Box]
            
            DT -->|Reduce Variance| RF[Random Forest<br>Bagging]
            DT -->|Reduce Bias| BOOST[AdaBoost<br>Boosting]
            
            NN -->|Image| CNN[CNN]
            NN -->|Sequence| RNN[RNN/LSTM]
            
            %% Unsupervised Branch
            ML --> UNSUP(Unsupervised<br>No Target Y)
            UNSUP --> CLUST[Clustering]
            CLUST --> KM[K-Means<br>Pre-set K]
            CLUST --> HIER[Hierarchical<br>Dendrogram]
            
            UNSUP --> DIM[Dimension Reduction]
            DIM --> PCA[PCA]
            
            %% Reinforcement Branch
            ML --> RL(Reinforcement)
            RL --> MAB[Multi-Armed Bandits]
            MAB --> TRADE[Exploration vs Exploitation]
        </div>
    </div>
</div>

<div id="tab-notes" class="tab-content">
    <div class="section-title">å„ç« è©³ç´°ç­†è¨˜ (Based on infs.docx)</div>
    
    <details>
        <summary>L1: Introduction (åŸºç¤æ¦‚å¿µ)</summary>
        <div class="note-body">
            <p><b>Analytics é¡å‹ (æŒ‰ç›®çš„åˆ†)ï¼š</b></p>
            <ul>
                <li><b>Descriptive:</b> ç™¼ç”Ÿäº†ä»€éº¼ï¼Ÿ(Hindsight)</li>
                <li><b>Diagnostic:</b> ç‚ºä½•ç™¼ç”Ÿï¼Ÿ</li>
                <li><b>Predictive:</b> æœªä¾†æœƒç™¼ç”Ÿä»€éº¼ï¼Ÿ(æœ¬èª²é‡é» Insight)</li>
                <li><b>Prescriptive:</b> æ‡‰è©²åšä»€éº¼ï¼Ÿ(Optimization/Foresight)</li>
            </ul>
            <p><b>Machine Learning åˆ†é¡ï¼š</b></p>
            <ul>
                <li><b>Supervised:</b> æœ‰æ¨™ç±¤ (Y)ã€‚ç”¨æ–¼é æ¸¬ã€‚</li>
                <li><b>Unsupervised:</b> ç„¡æ¨™ç±¤ã€‚æ‰¾è¦å¾‹ (Clustering, PCA)ã€‚</li>
                <li><b>Reinforcement:</b> Agent åœ¨ç’°å¢ƒè©¦éŒ¯ (Trial-and-error)ï¼Œç”¨ Reward å­¸ç¿’ (MAB)ã€‚</li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L2: Clustering & PCA (éç›£ç£)</summary>
        <div class="note-body">
            <p><b>Clustering (èšé¡)</b></p>
            <ul>
                <li><b>ç›®æ¨™ï¼š</b>çµ„å…§ç›¸ä¼¼ (Cohesion)ï¼Œçµ„é–“ä¸åŒ (Separation)ã€‚</li>
                <li><b>è·é›¢ï¼š</b>é€šå¸¸ç”¨ Euclideanã€‚<b>å¿…é ˆå…ˆåš Feature Scaling</b> (Standardization)ï¼Œå¦å‰‡å¤§æ•¸å€¼è®Šæ•¸æœƒä¸»å°è·é›¢ã€‚</li>
                <li><b>K-Means (Partitioning)ï¼š</b>
                    <ul>
                        <li>æ­¥é©Ÿï¼šé¸ K -> éš¨æ©Ÿä¸­å¿ƒ -> åˆ†é… -> æ›´æ–°ä¸­å¿ƒ -> é‡è¤‡ã€‚</li>
                        <li>ç¼ºé»ï¼šå°åˆå§‹é»æ•æ„Ÿã€å° Outlier æ•æ„Ÿã€åªæ“…é•·åœ“å½¢åˆ†ä½ˆã€‚</li>
                    </ul>
                </li>
                <li><b>Hierarchical (Agglomerative)ï¼š</b>
                    <ul>
                        <li>Bottom-up (æ¯å€‹é»é–‹å§‹æ˜¯ä¸€ç¾¤)ã€‚</li>
                        <li><b>Dendrogram:</b> åˆ‡ä¸€åˆ€æ±ºå®šç¾¤æ•¸ã€‚</li>
                        <li>Linkage: Single (æœ€è¿‘, é•·æ¢å½¢), Complete (æœ€é , åœ“å½¢)ã€‚</li>
                    </ul>
                </li>
                <li><b>è©•ä¼°ï¼š</b>Average Silhouette Score (æ¥è¿‘ 1 æœ€å¥½)ã€‚</li>
            </ul>
            <p><b>PCA (é™ç¶­)</b></p>
            <ul>
                <li>ç›®çš„ï¼šè§£æ±º Curse of Dimensionalityï¼Œæ¸›å°‘é‹ç®—ï¼Œå»é™¤å¤šé‡å…±ç·šæ€§ã€‚</li>
                <li><b>PC1:</b> è§£é‡‹æœ€å¤§è®Šç•°é‡ (Variance)ã€‚</li>
                <li>PC æ˜¯åŸè®Šæ•¸çš„ç·šæ€§çµ„åˆ (Linear Combination)ã€‚</li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L3: Linear & Logistic Regression</summary>
        <div class="note-body">
            <p><b>Linear Regression (ç·šæ€§å›æ­¸)</b></p>
            <ul>
                <li>Target: é€£çºŒæ•¸å€¼ã€‚</li>
                <li>ç›®æ¨™ï¼šæœ€å°åŒ– RSS (Residual Sum of Squares) æˆ– MSEã€‚</li>
                <li><b>RÂ²:</b> è§£é‡‹äº†å¤šå°‘è®Šç•°ã€‚åŠ è®Šæ•¸ RÂ² ä¸€å®šä¸Šå‡ (ä½†ä¸ä»£è¡¨æ¨¡å‹è®Šå¥½)ã€‚</li>
                <li><b>Multicollinearity:</b> è‡ªè®Šæ•¸é«˜åº¦ç›¸é—œï¼Œæœƒå°è‡´ä¿‚æ•¸ä¸ç©©ã€‚</li>
            </ul>
            <p><b>Logistic Regression (åˆ†é¡)</b></p>
            <ul>
                <li>Target: é¡åˆ¥ (0/1)ã€‚</li>
                <li>ä½¿ç”¨ <b>Sigmoid</b> å‡½æ•¸ (Så‹)ï¼Œå°‡è¼¸å‡ºå£“ç¸®åœ¨ 0-1 ä¹‹é–“ (æ©Ÿç‡)ã€‚</li>
                <li><b>Logit:</b> log(odds) æ˜¯ç·šæ€§çš„ã€‚</li>
                <li><b>Odds Ratio (OR):</b> exp(beta)ã€‚X å¢åŠ  1ï¼ŒOdds è®Šç‚º OR å€ã€‚</li>
            </ul>
            <p><b>è©•ä¼°æŒ‡æ¨™ (å¿…è€ƒ)</b></p>
            <ul>
                <li><b>Precision:</b> é æ¸¬ç‚º Positive ä¸­ï¼Œå¤šå°‘æ˜¯çœŸçš„ï¼Ÿ(é˜²èª¤å ± FP)ã€‚</li>
                <li><b>Recall:</b> å¯¦éš›ç‚º Positive ä¸­ï¼ŒæŠ“å‡ºå¤šå°‘ï¼Ÿ(é˜²æ¼å ± FNï¼Œå¦‚ Fraud/Cancer)ã€‚</li>
                <li><b>ROC/AUC:</b> 0.5 éš¨æ©Ÿï¼Œ1 å®Œç¾ã€‚</li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L4: Methodology & Regularization</summary>
        <div class="note-body">
            <p><b>Bias-Variance Tradeoff</b></p>
            <ul>
                <li>ç°¡å–®æ¨¡å‹ï¼šHigh Bias (Underfit), Low Varianceã€‚</li>
                <li>è¤‡é›œæ¨¡å‹ï¼šLow Bias, High Variance (Overfit)ã€‚</li>
                <li>ç›®æ¨™ï¼šæ‰¾ U å‹æ›²ç·šæœ€ä½é» (Generalization Error æœ€å°)ã€‚</li>
            </ul>
            <p><b>Regularization (è§£æ±º Overfitting)</b></p>
            <ul>
                <li>åœ¨ Loss Function åŠ å…¥ Penalty (alpha/lambda)ã€‚</li>
                <li><b>Lasso (L1):</b> ä¿‚æ•¸å¯è®Šç‚º 0 â†’ <b>ç‰¹å¾µé¸æ“‡ (Feature Selection)</b>ã€‚</li>
                <li><b>Ridge (L2):</b> ä¿‚æ•¸è®Šå°ä½†ä¸ç‚º 0 â†’ è™•ç†å¤šé‡å…±ç·šæ€§ã€‚</li>
                <li>æ³¨æ„ï¼šåš Regularization å‰å¿…é ˆå…ˆ Standardize æ•¸æ“šã€‚</li>
            </ul>
            <p><b>Workflow</b></p>
            <ul>
                <li>Train set: å­¸åƒæ•¸ã€‚</li>
                <li>Validation set: èª¿è¶…åƒæ•¸ (å¦‚ alpha)ã€‚(K-fold CV)</li>
                <li>Test set: æœ€çµ‚è©•ä¼° (åªç”¨ä¸€æ¬¡)ã€‚</li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L5: Decision Tree (æ±ºç­–æ¨¹)</summary>
        <div class="note-body">
            <ul>
                <li><b>åŸç†ï¼š</b> Recursive Partitioningã€‚æ‰¾æœ€ä½³ Split ä½¿ Loss é™æœ€å¤šã€‚</li>
                <li><b>å„ªé»ï¼š</b> æ˜“è§£é‡‹ (If-then rules)ï¼Œè™•ç†éç·šæ€§ & Interactionï¼Œä¸éœ€ Scalingã€‚</li>
                <li><b>Loss (Impurity)ï¼š</b>
                    <ul>
                        <li>Classification: Gini, Entropy (Info Gain)ã€‚</li>
                        <li>Regression: SSEã€‚</li>
                    </ul>
                </li>
                <li><b>ç¼ºé»ï¼š</b> å®¹æ˜“ Overfit (æ¨¹å¤ªæ·±)ã€‚</li>
                <li><b>è§£æ³•ï¼š</b> Pruning (å‰ªæ) æˆ– Ensembleã€‚</li>
                <li><b>C4.5/C5.0:</b> ä½¿ç”¨ Information Gain Ratio é¿å…åå¥½åˆ†æ”¯å¤šçš„è®Šæ•¸ã€‚</li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L7: ANN (é¡ç¥ç¶“ç¶²çµ¡)</summary>
        <div class="note-body">
            <ul>
                <li><b>çµæ§‹ï¼š</b> Input -> Hidden Layers -> Outputã€‚</li>
                <li><b>Activation Function (é‡è¦)ï¼š</b> å¼•å…¥<b>éç·šæ€§ (Non-linearity)</b>ã€‚å¸¸è¦‹ï¼šReLU (éš±è—å±¤), Sigmoid (è¼¸å‡ºå±¤)ã€‚è‹¥ç„¡ï¼ŒANN åªæ˜¯ç·šæ€§å›æ­¸ã€‚</li>
                <li><b>Forward:</b> è¨ˆç®—é æ¸¬å€¼ã€‚</li>
                <li><b>Backpropagation:</b> è¨ˆç®—èª¤å·®æ¢¯åº¦ï¼Œæ›´æ–°æ¬Šé‡ (Gradient Descent)ã€‚</li>
                <li>éœ€è¦å¤§é‡æ•¸æ“šï¼Œæ˜“ Overfit (éœ€ Dropout/Regularization)ï¼Œé»‘ç®±æ¨¡å‹ã€‚</li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L8: Ensemble (é›†æˆæ¨¡å‹)</summary>
        <div class="note-body">
            <p><b>Bagging (Bootstrap Aggregating)</b></p>
            <ul>
                <li><b>å¹³è¡Œ</b>å»ºç«‹å¤šå€‹æ¨¡å‹ã€‚</li>
                <li>å°æ•¸æ“šåš Bootstrap (æœ‰æ”¾å›æŠ½æ¨£)ã€‚</li>
                <li>ä¾‹å­ï¼š<b>Random Forest</b> (Bagging + éš¨æ©Ÿç‰¹å¾µé¸æ“‡)ã€‚</li>
                <li>ç›®çš„ï¼šé™ä½ <b>Variance</b> (ç©©å®šæ€§)ã€‚</li>
            </ul>
            <p><b>Boosting</b></p>
            <ul>
                <li><b>åºåˆ—</b>å»ºç«‹æ¨¡å‹ã€‚</li>
                <li>å¾Œä¸€å€‹æ¨¡å‹å°ˆæ³¨ä¿®æ­£å‰ä¸€å€‹æ¨¡å‹<b>åšéŒ¯</b>çš„æ¨£æœ¬ (åŠ æ¬Š)ã€‚</li>
                <li>ä¾‹å­ï¼š<b>AdaBoost</b>ã€‚</li>
                <li>ç›®çš„ï¼šé™ä½ <b>Bias</b> (æº–ç¢ºåº¦)ã€‚</li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L9: Multi-Armed Bandits (MAB)</summary>
        <div class="note-body">
            <ul>
                <li><b>å®šç¾©ï¼š</b> è³­å ´è€è™æ©Ÿå•é¡Œã€‚åœ¨æœ‰é™æ¬¡æ•¸å…§æœ€å¤§åŒ– Rewardã€‚</li>
                <li><b>æ ¸å¿ƒ Tradeoffï¼š</b>
                    <ul>
                        <li><b>Exploration (æ¢ç´¢)ï¼š</b> è©¦æ–° Arm (å¯èƒ½æ›´å¥½)ã€‚</li>
                        <li><b>Exploitation (åˆ©ç”¨)ï¼š</b> é¸ç›®å‰æœ€å¥½ (è³º Reward)ã€‚</li>
                    </ul>
                </li>
                <li><b>ç­–ç•¥ï¼š</b>
                    <ul>
                        <li>Random: Baselineã€‚</li>
                        <li>Epsilon-Greedy: å¤§éƒ¨åˆ† Exploitï¼Œå°‘éƒ¨åˆ† (epsilon) Random Exploreã€‚</li>
                        <li>Thompson Sampling: Bayesian æ–¹æ³•ï¼Œå¾ Posterior æŠ½æ¨£ã€‚</li>
                    </ul>
                </li>
            </ul>
        </div>
    </details>

    <details>
        <summary>L10: CNN & Future AI</summary>
        <div class="note-body">
            <p><b>CNN (å·ç©ç¥ç¶“ç¶²çµ¡)</b></p>
            <ul>
                <li>å°ˆç”¨æ–¼åœ–åƒ (Image)ã€‚</li>
                <li><b>Convolution Layer:</b> Filter/Kernel æ»‘å‹•æå–å±€éƒ¨ç‰¹å¾µ (Local patterns: edge, corner)ã€‚å…±äº«æ¬Šé‡ (åƒæ•¸å°‘)ã€‚</li>
                <li><b>Pooling Layer:</b> é™ç¶­ (Down-sampling)ï¼Œä¿ç•™é¡¯è‘—ç‰¹å¾µï¼Œä¸è®Šæ€§ (Invariance)ã€‚</li>
            </ul>
            <p><b>Future of AI</b></p>
            <ul>
                <li>Generative AI (LLM): Transformer æ¶æ§‹ã€‚</li>
                <li>Ethics, Fairness, Explainabilityã€‚</li>
            </ul>
        </div>
    </details>
</div>

<div id="tab-bank" class="tab-content">
    <div class="section-title">äº’å‹•å¼é¡Œåº« (é»æ“Šé¸é …æŸ¥çœ‹ç­”æ¡ˆ)</div>
    
    <div id="bank-filters" style="margin-bottom:15px; display:flex; overflow-x:auto; gap:10px; padding-bottom:5px;">
        <button class="filter-btn active" onclick="filterBank('all')">å…¨éƒ¨</button>
        <button class="filter-btn" onclick="filterBank('L1')">L1</button>
        <button class="filter-btn" onclick="filterBank('L2')">L2</button>
        <button class="filter-btn" onclick="filterBank('L3')">L3</button>
        <button class="filter-btn" onclick="filterBank('L4')">L4</button>
        <button class="filter-btn" onclick="filterBank('L5')">L5</button>
        <button class="filter-btn" onclick="filterBank('L7')">L7</button>
        <button class="filter-btn" onclick="filterBank('L8')">L8</button>
        <button class="filter-btn" onclick="filterBank('L9')">L9</button>
        <button class="filter-btn" onclick="filterBank('L10')">L10</button>
        <button class="filter-btn" onclick="filterBank('Practice')">Practice</button>
    </div>

    <div id="bank-container"></div>
</div>

<div id="tab-quiz" class="tab-content">
    <div id="quiz-intro" class="card" style="text-align:center; padding:30px;">
        <h2>âš¡ AI æ¨¡æ“¬æ¸¬é©—</h2>
        <p>ç³»çµ±å°‡å¾é¡Œåº«ä¸­éš¨æ©ŸæŠ½å– 10 é¡Œã€‚</p>
        <button class="btn-primary" onclick="startQuiz()">é–‹å§‹æ¸¬é©—</button>
    </div>

    <div id="quiz-area" style="display:none;">
        <div class="card">
            <div style="display:flex; justify-content:space-between; color:#666; margin-bottom:10px;">
                <span id="q-progress"></span>
                <span id="q-score"></span>
            </div>
            <div id="quiz-question-container"></div>
        </div>
    </div>

    <div id="quiz-result" class="card" style="display:none; text-align:center; padding:30px;">
        <h2>æ¸¬é©—çµæŸ</h2>
        <div style="font-size:3rem; font-weight:bold; color:var(--primary); margin:20px 0;" id="final-score"></div>
        <p id="final-msg"></p>
        <button class="btn-primary" onclick="startQuiz()">å†æ¸¬ä¸€æ¬¡</button>
    </div>
</div>

<nav>
    <div class="nav-item active" onclick="switchTab('tab-outline', this)">
        <span class="nav-icon">ğŸ“‹</span>å¤§ç¶±
    </div>
    <div class="nav-item" onclick="switchTab('tab-mindmap', this)">
        <span class="nav-icon">ğŸ§ </span>åœ–è­œ
    </div>
    <div class="nav-item" onclick="switchTab('tab-notes', this)">
        <span class="nav-icon">ğŸ“</span>ç­†è¨˜
    </div>
    <div class="nav-item" onclick="switchTab('tab-bank', this)">
        <span class="nav-icon">ğŸ“š</span>é¡Œåº«
    </div>
    <div class="nav-item" onclick="switchTab('tab-quiz', this)">
        <span class="nav-icon">âš¡</span>æ¨¡è€ƒ
    </div>
</nav>

<style>
    .filter-btn {
        background: #fff; border: 1px solid #ddd; border-radius: 15px; padding: 5px 12px; font-size: 0.85rem; white-space: nowrap;
    }
    .filter-btn.active {
        background: var(--primary); color: white; border-color: var(--primary);
    }
</style>

<script>
    // åˆå§‹åŒ– Mermaid
    mermaid.initialize({ startOnLoad: true, theme: 'default' });

    // --- Data: Complete Question Bank ---
    const questionBank = [
        // L1 Kahoot
        { cat: "L1", q: "Which option represents some level of Artificial Intelligence?", opts: ["Calculator", "Computer", "Self-driving car", "Laundry Machine"], ans: 2, exp: "Self-driving cars involve perception, decision making, and learning (AI). Calculators are rule-based." },
        { cat: "L1", q: "Market segmentation is a problem under Supervised Machine Learning.", opts: ["True", "False"], ans: 1, exp: "False. Market segmentation typically has no labels (target variable) and groups data based on similarities, making it Unsupervised (Clustering)." },
        { cat: "L1", q: "Series have index and actual data, so it is 2-dimensional with 2 columns.", opts: ["True", "False"], ans: 1, exp: "False. A Series is 1-dimensional." },
        { cat: "L1", q: "One column from a DataFrame is a Series.", opts: ["True", "False"], ans: 0, exp: "True. In Pandas, a single column of a DataFrame is a Series." },
        { cat: "L1", q: "What is an example of Topic Model?", opts: ["Label each of Australian Gov's update as positive or negative", "Find topics from Australian Gov's updates in the past year"], ans: 1, exp: "Labeling is sentiment analysis (Supervised). Finding topics is Unsupervised (Topic Modeling)." },
        { cat: "L1", q: "Document-term matrix is normally sparse and have many zeros.", opts: ["True", "False"], ans: 0, exp: "True. Most documents only contain a small subset of the total vocabulary." },
        { cat: "L1", q: "Why do we truncate the Singular Value Decomposition (SVD)?", opts: ["To find all potential topics", "To keep only a few top-ranked topics"], ans: 1, exp: "Truncation keeps the most significant singular values (concepts) and removes noise." },
        { cat: "L1", q: "What does GPT stand for in ChatGPT?", opts: ["Guide for Personal Tasks", "Generated Personal Tutor", "Generative Pre-trained Transformer", "Galvatron Prime Transformer"], ans: 2, exp: "Generative Pre-trained Transformer." },

        // L2 Kahoot
        { cat: "L2", q: "Which one is FALSE about clustering?", opts: ["Each cluster is a subset of the data set", "The union of all clusters is equivalent to the entire data set", "Two clusters can have common observations", "Within a cluster, observations should be similar"], ans: 2, exp: "In standard hard clustering, partitions are distinct; observations belong to only one cluster (intersection is empty)." },
        { cat: "L2", q: "We separate a customer base into four groups based on Male/Female and age group. This is clustering.", opts: ["True", "False"], ans: 1, exp: "False. This is segmentation based on rules, not machine learning clustering which finds hidden patterns based on data." },
        { cat: "L2", q: "Which one is FALSE about Euclidean Distance?", opts: ["No variable can dominate other variables", "It is the sqrt of 'sum of squared differences'", "Feature scaling can ensure variables have similar range", "Categorical variable converted to integer can overshadow continuous variable"], ans: 0, exp: "Euclidean distance IS sensitive to scale. Large magnitude variables WILL dominate without scaling." },
        { cat: "L2", q: "Complete linkage measures the minimum distance of all possible combinations of observations in two clusters.", opts: ["True", "False"], ans: 1, exp: "False. Complete linkage uses the MAXIMUM distance. Single linkage uses Minimum." },
        { cat: "L2", q: "What is FALSE about Agglomerative Clustering?", opts: ["It merges all observations hierarchically", "Constructing n*n proximity matrix can be computationally expensive", "We can use single, complete, average, or ward's linkage", "The final outcome is one cluster, regardless of the distance threshold"], ans: 3, exp: "The final outcome depends on where you cut the dendrogram (distance threshold). It doesn't have to be one cluster." },
        { cat: "L2", q: "What is FALSE about K-Means?", opts: ["We start with randomly selected K centroids", "In each round we assign each point to the nearest centroid", "If we start K-Means with K=3, we might end up with a 2-cluster result", "We stop when no change in membership and centroids"], ans: 2, exp: "K-Means forces K clusters. It won't automatically reduce to 2 if you asked for 3 (unless a cluster becomes empty, which is rare/handled)." },
        { cat: "L2", q: "What is Average Silhouette Score NOT about?", opts: ["How close observations are within a cluster", "How far each cluster is from other clusters", "Whether each observation is in the right cluster"], ans: 2, exp: "Clustering is unsupervised, so there is no 'right' cluster (ground truth). Silhouette measures cohesion and separation." },
        { cat: "L2", q: "Principal Components usually cannot be interpreted to variables in real life.", opts: ["True", "False"], ans: 0, exp: "True. PCs are linear combinations of original variables, making them abstract." },

        // L3 Kahoot
        { cat: "L3", q: "Which option is FALSE about the linear regression model?", opts: ["y is the target variable", "x is the input variable", "beta0 is the intercept", "beta0 is the gradient of the fitted line"], ans: 3, exp: "Beta0 is the intercept. Beta1 is the gradient/slope." },
        { cat: "L3", q: "Which option is FALSE about Multiple Linear Regression (MLR) and RÂ²?", opts: ["MLR allows ceteris paribus analysis", "If RÂ² gets higher, the model definitely becomes a better fit", "As we include more input variables, RÂ² usually increases", "MLR assumes that no input variable is constant"], ans: 1, exp: "Higher RÂ² doesn't always mean a better model; it could be overfitting." },
        { cat: "L3", q: "A positive coefficient for xi in MLR implies that y and xi are positively correlated.", opts: ["True", "False"], ans: 1, exp: "False. In MLR, coefficients are 'Ceteris Paribus'. Multicollinearity can cause signs to flip compared to simple correlation." },
        { cat: "L3", q: "Which coefficient indicates the vertical height difference between two lines? y = b0 + b1*d + b2*area", opts: ["b0", "b1", "b2", "y"], ans: 1, exp: "If d is a dummy variable (0 or 1), b1 represents the shift/difference in intercept (vertical height)." },
        { cat: "L3", q: "If a categorical variable has 10 values, how many dummy variables are needed?", opts: ["8", "9", "10", "11"], ans: 1, exp: "k-1 rule. 10 categories need 9 dummy variables." },
        { cat: "L3", q: "Which option is FALSE about training vs. testing set?", opts: ["Training set contains input variables and known target", "Testing set should be bigger than training set", "Testing set contains input variables but hidden target", "Testing set is not used for training"], ans: 1, exp: "Training set should be larger (e.g., 70/30 split)." },
        { cat: "L3", q: "Logistic Regression is more suitable as a classifier than Linear Regression.", opts: ["True", "False"], ans: 0, exp: "True. Linear regression outputs unbounded values; Logistic outputs probabilities (0-1)." },
        { cat: "L3", q: "What is the odds of a coin toss being head (70% chance)?", opts: ["3/7", "1", "7/3", "0"], ans: 2, exp: "Odds = P / (1-P) = 0.7 / 0.3 = 7/3." },
        { cat: "L3", q: "Which sum below equals 1?", opts: ["TPR + FPR", "TNR + FNR", "TPR + FNR", "Precision + TPR"], ans: 2, exp: "TPR + FNR = 1. (All actual positives are either identified (TP) or missed (FN))." },
        { cat: "L3", q: "Which model should optimize for Recall? (False negative is critical)", opts: ["YouTube ad predicted 'not favored'", "Earthquake model predicts negative but earthquake is coming"], ans: 1, exp: "Missing an earthquake (FN) is dangerous. High Recall needed." },

        // L4 Kahoot
        { cat: "L4", q: "If a model is considered low Bias and high Variance, which description is correct?", opts: ["Complex model; underfitting", "Complex model; overfitting", "Simple model; underfitting", "Simple model; overfitting"], ans: 1, exp: "High Variance = Overfitting (Complex model)." },
        { cat: "L4", q: "If the number of terms for a regression equation is 5, what is the minimum number of observations ideally?", opts: ["30", "40", "50", "60"], ans: 2, exp: "Rule of thumb: 10 observations per predictor. 5 * 10 = 50." },
        { cat: "L4", q: "If penalty weight alpha is large, coefficients are all limited to a small space.", opts: ["True", "False"], ans: 0, exp: "True. Large alpha = strong penalty = smaller coefficients." },
        { cat: "L4", q: "Which regularization produces sparse coefficients?", opts: ["LASSO", "Ridge"], ans: 0, exp: "LASSO (L1) drives coefficients to zero." },
        { cat: "L4", q: "Which option is FALSE about train-validation-test method?", opts: ["Testing set can only be used once at the end", "Testing set should contain a wide range of different observations", "Validation set can only be used once for training", "Validation set can be used to fine-tune model parameters"], ans: 2, exp: "Validation set is used repeatedly to tune parameters." },
        { cat: "L4", q: "k-fold Cross-Validation has a special flavor called 'Leave-one-out', suitable for very small datasets.", opts: ["True", "False"], ans: 0, exp: "True." },
        { cat: "L4", q: "When variable area changes from sq meters to sq feet (value increases), what is the implication in regularization?", opts: ["Value goes down; less penalty", "Value goes up; more penalty", "Value goes down; more penalty", "Value goes up; less penalty"], ans: 3, exp: "If inputs are larger (sq feet), the coefficient becomes smaller to match Y. Smaller coefficients incur LESS penalty. (That's why scaling is required!)" },
        { cat: "L4", q: "When we have very big datasets, we usually prefer complex models.", opts: ["True", "False"], ans: 0, exp: "True. With more data, we can support more complexity (lower bias) without high variance." },
        { cat: "L4", q: "If y is 90% True in the train set, the model is likely to predict all rows to have y= False.", opts: ["True", "False"], ans: 1, exp: "False. It will likely predict all True (the majority class)." },
        { cat: "L4", q: "What is NOT the purpose of regularization?", opts: ["Address overfitting", "Prevent overly complicated model", "Reduce coefficients of irrelevant variables", "Find the perfect model for the training dataset"], ans: 3, exp: "Regularization sacrifices training accuracy (increases bias) to improve generalization. It deliberately does NOT find the 'perfect fit' for training data." },

        // L5 Kahoot
        { cat: "L5", q: "Which statement is FALSE about decision trees?", opts: ["They perform automatic feature selection", "They can handle both numeric and categorical data", "Deep trees are less likely to overfit", "Trees split based on impurity reduction"], ans: 2, exp: "Deep trees are MORE likely to overfit." },
        { cat: "L5", q: "Correct interpretation of Gini impurity?", opts: ["Measures how many nodes", "Measures randomness / impurity of the split", "Total error", "Number of leaves"], ans: 1, exp: "Gini measures impurity. 0 is pure." },
        { cat: "L5", q: "Which is TRUE about entropy?", opts: ["Always negative", "Equals 0 when the node is pure", "Increases when node is purer", "Unrelated to information gain"], ans: 1, exp: "Entropy is 0 for a pure node." },
        { cat: "L5", q: "Which technique helps prevent overfitting in decision trees?", opts: ["Increasing depth", "Adding more variables", "Pruning", "Increasing number of leaves"], ans: 2, exp: "Pruning cuts back the tree." },
        { cat: "L5", q: "Which statement about Random Forest is FALSE?", opts: ["Uses bagging", "Reduces variance", "Uses boosting", "Uses multiple decision trees"], ans: 2, exp: "Random Forest uses Bagging, not Boosting." },
        { cat: "L5", q: "In Random Forest, what does 'feature bagging' mean?", opts: ["Using all features", "Using a random subset of features for splitting", "Using PCA", "Removing correlated features"], ans: 1, exp: "At each split, only a random subset of features is considered." },
        { cat: "L5", q: "Which one is TRUE for decision trees?", opts: ["Very interpretable compared to other ML models", "Requires heavy data preprocessing", "Only works for classification", "Cannot handle missing values"], ans: 0, exp: "They are White Box models (Rules)." },
        { cat: "L5", q: "What happens if a tree grows too deep?", opts: ["Model underfits", "Model generalizes perfectly", "Model overfits", "No change"], ans: 2, exp: "Overfits." },

        // L7 Kahoot
        { cat: "L7", q: "Which activation function outputs values between 0 and 1?", opts: ["ReLU", "Sigmoid", "Tanh", "Linear"], ans: 1, exp: "Sigmoid." },
        { cat: "L7", q: "Which statement about neural networks is TRUE?", opts: ["Cannot model non-linear", "Require activation functions for non-linearity", "Only work for images", "Always outperform logistic regression"], ans: 1, exp: "Without activation functions, NNs are just linear models." },
        { cat: "L7", q: "What is backpropagation used for?", opts: ["Model evaluation", "Updating weights", "Increasing dataset size", "Handling missing values"], ans: 1, exp: "Calculating gradients to update weights." },
        { cat: "L7", q: "Which is a disadvantage of neural networks?", opts: ["Highly interpretable", "Require large datasets", "Always converge to global minimum", "Do not need hyperparameter tuning"], ans: 1, exp: "They need a lot of data to learn." },
        { cat: "L7", q: "Which is an example of hyperparameter?", opts: ["Weight values", "Bias values", "Learning rate", "Activation output"], ans: 2, exp: "Weights/Bias are parameters (learned). Learning rate is set by user (hyperparameter)." },
        { cat: "L7", q: "Which option describes overfitting in neural networks?", opts: ["Training loss down, Test loss down", "Training loss down, Test loss up", "Training loss up, Test loss down", "Training loss up, Test loss up"], ans: 1, exp: "Memorizing training data (low loss) but failing on test data (high loss)." },

        // L8 Kahoot
        { cat: "L8", q: "Which is TRUE about ensemble models?", opts: ["Always reduce variance", "Combine predictions from multiple models", "Always reduce bias", "Always improve interpretability"], ans: 1, exp: "Definition of ensemble." },
        { cat: "L8", q: "Which method is boosting?", opts: ["Random Forest", "XGBoost", "Bagging", "Feature selection"], ans: 1, exp: "XGBoost (eXtreme Gradient Boosting)." },
        { cat: "L8", q: "In bagging, models are trained on:", opts: ["Identical datasets", "Random samples with replacement", "Random samples without replacement", "Only misclassified observations"], ans: 1, exp: "Bootstrap = Sampling with replacement." },
        { cat: "L8", q: "Main idea of boosting?", opts: ["Train many deep trees", "Reduce bias by sequentially improving weak learners", "Reduce variance by parallel models", "Remove correlated features"], ans: 1, exp: "Sequential improvement." },
        { cat: "L8", q: "Which is NOT an ensemble method?", opts: ["Stacking", "Boosting", "Bagging", "Normalization"], ans: 3, exp: "Normalization is preprocessing." },
        { cat: "L8", q: "Which is TRUE about XGBoost?", opts: ["Uses pruning", "Uses gradient boosting", "Always outperforms RF", "Cannot handle missing values"], ans: 1, exp: "It is a gradient boosting library." },

        // L9 Kahoot
        { cat: "L9", q: "Which option is TRUE about confusion matrix?", opts: ["Shows model weights", "Shows classification performance", "Shows hyperparameters", "Represents model size"], ans: 1, exp: "Shows TP/TN/FP/FN." },
        { cat: "L9", q: "Which is a good metric when classes are imbalanced?", opts: ["Accuracy", "Precision", "Recall", "F1 Score"], ans: 3, exp: "F1 Score balances Precision and Recall." },
        { cat: "L9", q: "What does ROC curve represent?", opts: ["TPR vs FPR", "Training loss", "Model complexity", "Total error"], ans: 0, exp: "True Positive Rate vs False Positive Rate." },
        { cat: "L9", q: "Which statement is TRUE about AUC?", opts: ["Higher AUC means worse model", "AUC must be 1", "AUC indicates separability", "AUC is unrelated to ROC"], ans: 2, exp: "Area Under Curve indicates how well model separates classes." },
        { cat: "L9", q: "Cross-validation helps with:", opts: ["Reducing bias", "Reducing variance", "Reducing overfitting", "All of the above"], ans: 3, exp: "It helps estimate performance more reliably." },
        { cat: "L9", q: "Which is TRUE about baseline models?", opts: ["Use deep learning", "Are complex", "Provide point of comparison", "Require tuning"], ans: 2, exp: "Baselines (like 'predict all 0') give a benchmark." },

        // L10 Kahoot
        { cat: "L10", q: "Semantic Segmentation and Instance Segmentation are the same.", opts: ["True", "False"], ans: 1, exp: "False. Semantic labels pixels by class (e.g., 'car'). Instance distinguishes 'car 1' from 'car 2'." },
        { cat: "L10", q: "Why are CNNs superior to fully-connected networks for image tasks?", opts: ["Capture local spatial patterns", "Require less computation", "Excel at time series", "Better interpretability"], ans: 0, exp: "Convolutional layers capture spatial hierarchy." },
        { cat: "L10", q: "Primary purpose of convolution operation:", opts: ["Non-linear activation", "Weight regularization", "Feature extraction", "Dimensionality reduction"], ans: 2, exp: "Extracts features like edges." },
        { cat: "L10", q: "Activation functions introduce non-linearity into CNNs.", opts: ["True", "False"], ans: 0, exp: "True." },
        { cat: "L10", q: "Primary purpose of pooling layer:", opts: ["Feature extraction", "Non-linearity", "Dimensionality reduction", "Weight regularization"], ans: 2, exp: "Down-sampling." },

        // Practice Questions PDF
        { cat: "Practice", q: "1. Which describes underfitting?", opts: ["High Var/High Bias", "High Var/Low Bias", "Low Var/High Bias", "Low Var/Low Bias"], ans: 2, exp: "Simple model = High Bias." },
        { cat: "Practice", q: "2. How does Ridge regularization mitigate overfitting?", opts: ["Reduce bias and variance", "Increase bias a bit and reduce variance", "Reduce bias and increase variance", "Increase bias and variance"], ans: 1, exp: "Trade-off: Sacrifice some bias (simpler model) to lower variance." },
        { cat: "Practice", q: "3. How will training set's RÂ² move, as the model complexity increases?", opts: ["Down then up", "Up then down", "Always goes down", "Always goes up"], ans: 3, exp: "Training error always decreases (R2 increases) with complexity." },
        { cat: "Practice", q: "4. What is the purpose of validation set?", opts: ["Memorize training data", "Prevent overfitting/Tune hyperparameters", "Final testing", "Increase training size"], ans: 1, exp: "Tuning and checking overfitting." },
        { cat: "Practice", q: "5. Target y is binary (30% 0, 70% 1). Best training accuracy if guessing one class?", opts: ["30%", "70%", "50%", "Depends"], ans: 1, exp: "Guessing '1' gives 70% accuracy." },
        { cat: "Practice", q: "6. Problem for Logistic Regression?", opts: ["Regression", "MAB", "Binary classification", "Clustering"], ans: 2, exp: "Classification." },
        { cat: "Practice", q: "7. In C5.0, how to prevent favoritism to inputs with many splits?", opts: ["Random noise", "Equal chance", "Information Gain Ratio", "Favors binary"], ans: 2, exp: "Information Gain Ratio penalizes variables with many branches." },
        { cat: "Practice", q: "8. Which is FALSE about neural networks?", opts: ["Highly interpretable", "Require large data", "Computationally heavy", "Prone to overfitting"], ans: 0, exp: "They are black boxes." },
        { cat: "Practice", q: "9. What is TRUE about AdaBoost?", opts: ["Equal weight", "Less sensitive to noise", "Single powerful model", "Adapts to mistakes"], ans: 3, exp: "Adapts to mistakes of previous models." },
        { cat: "Practice", q: "10. TRUE about exploration-exploitation trade-off?", opts: ["Balancing helps discover best arm", "Maximizing exploration is fast", "Exploitation gathers info", "Exploration is immediate reward"], ans: 0, exp: "Balance is key." }
    ];

    // --- Tab Switching ---
    function switchTab(id, navEl) {
        document.querySelectorAll('.tab-content').forEach(el => el.classList.remove('active'));
        document.getElementById(id).classList.add('active');
        document.querySelectorAll('.nav-item').forEach(el => el.classList.remove('active'));
        navEl.classList.add('active');
        window.scrollTo(0,0);
        
        if(id === 'tab-bank') filterBank('all');
    }

    // --- Question Bank Logic ---
    function filterBank(cat) {
        document.querySelectorAll('.filter-btn').forEach(btn => btn.classList.remove('active'));
        event.target.classList.add('active');
        renderBank(cat);
    }

    function renderBank(cat) {
        const container = document.getElementById('bank-content');
        container.innerHTML = '';
        
        const filtered = cat === 'all' ? questionBank : questionBank.filter(q => q.cat === cat);
        
        filtered.forEach((item, idx) => {
            const div = document.createElement('div');
            div.className = 'q-card';
            div.innerHTML = `
                <div class="q-header"><span>#${idx+1}</span><span>[${item.cat}]</span></div>
                <div class="q-text">${item.q}</div>
                <div class="q-options" id="bank-q-${idx}">
                    ${item.opts.map((opt, i) => `
                        <div class="q-opt" onclick="revealBankAnswer(this, ${i}, ${item.ans}, 'bank-exp-${idx}')">${String.fromCharCode(65+i)}. ${opt}</div>
                    `).join('')}
                </div>
                <div id="bank-exp-${idx}" class="q-exp">ğŸ’¡ <b>Explanation:</b> ${item.exp}</div>
            `;
            container.appendChild(div);
        });
    }

    function revealBankAnswer(el, selected, correct, expId) {
        const parent = el.parentElement;
        if(parent.classList.contains('answered')) return; // Prevent re-click
        parent.classList.add('answered');

        const opts = parent.getElementsByClassName('q-opt');
        if(selected === correct) {
            el.classList.add('correct');
        } else {
            el.classList.add('wrong');
            opts[correct].classList.add('correct');
        }
        document.getElementById(expId).style.display = 'block';
    }

    // --- Quiz Logic ---
    let quizQueue = [];
    let currentQuizIdx = 0;
    let quizScore = 0;

    function startQuiz() {
        quizQueue = [...questionBank].sort(() => 0.5 - Math.random()).slice(0, 10);
        currentQuizIdx = 0;
        quizScore = 0;
        
        document.getElementById('quiz-start-view').style.display = 'none';
        document.getElementById('quiz-result-view').style.display = 'none';
        document.getElementById('quiz-play-view').style.display = 'block';
        
        renderQuizQuestion();
    }

    function renderQuizQuestion() {
        const q = quizQueue[currentQuizIdx];
        document.getElementById('quiz-counter').innerText = `Question ${currentQuizIdx + 1}/10`;
        document.getElementById('quiz-score').innerText = `Score: ${quizScore}`;
        document.getElementById('quiz-question-text').innerText = q.q;
        document.getElementById('quiz-explanation').style.display = 'none';
        document.getElementById('quiz-next-btn').style.display = 'none';

        const container = document.getElementById('quiz-options');
        container.innerHTML = '';
        container.classList.remove('answered');

        q.opts.forEach((opt, i) => {
            const div = document.createElement('div');
            div.className = 'q-opt';
            div.innerText = opt;
            div.onclick = () => checkQuizAnswer(div, i, q.ans, q.exp);
            container.appendChild(div);
        });
    }

    function checkQuizAnswer(el, selected, correct, expText) {
        const parent = document.getElementById('quiz-options');
        if(parent.classList.contains('answered')) return;
        parent.classList.add('answered');

        const opts = parent.getElementsByClassName('q-opt');
        
        if(selected === correct) {
            el.classList.add('correct');
            quizScore += 10;
            document.getElementById('quiz-score').innerText = `Score: ${quizScore}`;
        } else {
            el.classList.add('wrong');
            opts[correct].classList.add('correct');
        }

        const expDiv = document.getElementById('quiz-explanation');
        expDiv.innerHTML = `ğŸ’¡ <b>Explanation:</b> ${expText}`;
        expDiv.style.display = 'block';
        
        const nextBtn = document.getElementById('quiz-next-btn');
        if(currentQuizIdx === 9) nextBtn.innerText = "Finish Quiz";
        else nextBtn.innerText = "Next Question";
        nextBtn.style.display = 'block';
    }

    function nextQuizQuestion() {
        currentQuizIdx++;
        if(currentQuizIdx < 10) {
            renderQuizQuestion();
        } else {
            finishQuiz();
        }
    }

    function finishQuiz() {
        document.getElementById('quiz-play-view').style.display = 'none';
        document.getElementById('quiz-result-view').style.display = 'block';
        document.getElementById('final-score').innerText = quizScore;
        
        let msg = "";
        if(quizScore >= 80) msg = "Awesome! You are ready!";
        else if(quizScore >= 60) msg = "Good pass! Review the notes.";
        else msg = "Keep practicing! Check the explanations.";
        document.getElementById('final-msg').innerText = msg;
    }

    // Load initial
    document.addEventListener("DOMContentLoaded", () => {
        // filterBank('all'); // Load questions on start if needed, currently lazy loaded on tab switch
    });

</script>

</body>
</html>
